{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content-based Recommendation Baseline\n",
    "\n",
    "Inspired by [Deep content-based music recommendation](https://papers.nips.cc/paper/5004-deep-content-based-music-recommendation.pdf) by van den Oord, Dieleman \n",
    "\n",
    "Instead of using MFCC, which would require getting the music files, we use the timbre features which are already provided by the EchoNest API. Code here is taken from/based on the source for the [Notebooks](https://github.com/dawenl/stochastic_PMF) for [Codebook-based Scalable Music Tagging with Poisson Matrix Factorization](http://dawenl.github.io/publications/LiangPE14-codebook.pdf) by Dawen Liang, John Paisley and Dan Ellis, in ISMIR 2014, with slight modifications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Vector Quantized Representations of Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from constants import SubsetDataset, TasteProfileDataset, MSDChallengeDataset\n",
    "from lib import hdf5_getters\n",
    "from lib.hartigan import HartiganOnline\n",
    "from lib.quantize import VectorQuantizer\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_all_unique_tracks(ConstantClass, cache_dir=os.path.join(\".\", \"data\", \"cache\")):\n",
    "    tracks = set()\n",
    "    track_to_song_mappings = defaultdict(list)\n",
    "    song_to_track_mappings = {}\n",
    "    track_cache_path = os.path.join(cache_dir, \"tracks.json\")\n",
    "    track_to_song_cache_path = os.path.join(cache_dir, \"track_to_song.json\")\n",
    "    song_to_track_cache_path = os.path.join(cache_dir, \"song_to_track.json\")\n",
    "\n",
    "    if os.path.exists(track_cache_path) and os.path.exists(track_to_song_cache_path) and os.path.exists(song_to_track_cache_path):\n",
    "        track_cache_f = open(track_cache_path, \"r\")\n",
    "        track_to_song_cache_f = open(track_to_song_cache_path, \"r\")\n",
    "        song_to_track_cache_f = open(song_to_track_cache_path, \"r\")\n",
    "        \n",
    "        tracks = json.load(track_cache_f)\n",
    "        track_to_song_mappings = json.load(track_to_song_cache_f)\n",
    "        song_to_track_mappings = json.load(song_to_track_cache_f)\n",
    "        \n",
    "        track_cache_f.close()\n",
    "        track_to_song_cache_f.close()\n",
    "        song_to_track_cache_f.close()\n",
    "        \n",
    "        return tracks, track_to_song_mappings, song_to_track_mappings\n",
    "\n",
    "    with open(ConstantClass.MSD_UNIQ_TRACKS_PATH, 'rb') as f:\n",
    "        for (count, line) in enumerate(f):\n",
    "            track_id, _, _, _ = line.decode(\"utf-8\").strip().split(\"<SEP>\")\n",
    "            tracks.add(track_id)\n",
    "            \n",
    "            track_dir = os.path.join(ConstantClass.MSD_DATA_DIR, '/'.join(track_id[2:5]), f'{track_id}.h5')\n",
    "            h5 = hdf5_getters.open_h5_file_read(track_dir)\n",
    "            for i in range(hdf5_getters.get_num_songs(h5)):\n",
    "                song_id = hdf5_getters.get_song_id(h5, i).decode('utf-8')\n",
    "                track_to_song_mappings[track_id].append(song_id)\n",
    "                song_to_track_mappings[song_id] = track_id\n",
    "            h5.close()\n",
    "            \n",
    "            if count % 1000 == 0:\n",
    "                print(f\"{count} tracks processed\")\n",
    "\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir)\n",
    "    \n",
    "    tracks = list(tracks)\n",
    "    \n",
    "    with open(track_cache_path, \"w\") as f:\n",
    "        json.dump(tracks, f)\n",
    "    \n",
    "    with open(track_to_song_cache_path, \"w\") as f:\n",
    "        json.dump(track_to_song_mappings, f)\n",
    "    \n",
    "    with open(song_to_track_cache_path, \"w\") as f:\n",
    "        json.dump(song_to_track_mappings, f)\n",
    "    \n",
    "    return tracks, track_to_song_mappings, song_to_track_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uniq_tracks, track_id_to_song_id, song_id_to_track_id = get_all_unique_tracks(SubsetDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Quantization\n",
    "\n",
    "VQ allows us to get a feature representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def data_generator(ConstantClass, tracks, shuffle=True, ext=\".h5\"):\n",
    "    if shuffle:\n",
    "        np.random.shuffle(list(tracks))\n",
    "\n",
    "    for track_id in tracks:\n",
    "        track_dir = os.path.join(ConstantClass.MSD_DATA_DIR, '/'.join(track_id[2:5]), track_id + ext)\n",
    "        h5 = hdf5_getters.open_h5_file_read(track_dir)\n",
    "        for i in range(hdf5_getters.get_num_songs(h5)):\n",
    "            timbre = hdf5_getters.get_segments_timbre(h5, i)\n",
    "            if shuffle:\n",
    "                np.random.shuffle(timbre)\n",
    "            yield timbre\n",
    "        h5.close()\n",
    "\n",
    "\n",
    "def build_codewords(ConstantClass, tracks, n_clusters=2, max_iter=10, random_state=None, cluster=None):\n",
    "    if type(random_state) is int:\n",
    "        np.random.seed(random_state)\n",
    "    elif random_state is not None:\n",
    "        np.random.set_state(random_state)\n",
    " \n",
    "    if cluster is None:\n",
    "        cluster = HartiganOnline(n_clusters)\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        print(f\"Iteration {i+1}: Passing through the data...\")\n",
    "        for d in data_generator(ConstantClass, tracks):\n",
    "            cluster.partial_fit(d)\n",
    "\n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_codewords(ConstantClass, tracks, n_clusters, max_iter, random_state, cache_dir=os.path.join(\".\", \"data\", \"cache\")):\n",
    "    cache_path = os.path.join(cache_dir, \"cluster.pkl\")\n",
    "    \n",
    "    if os.path.exists(cache_path):\n",
    "        with open(cache_path, \"rb\") as f:\n",
    "            cluster = pickle.load(f)\n",
    "            return cluster\n",
    "\n",
    "    cluster = build_codewords(ConstantClass, tracks, n_clusters, max_iter, random_state)\n",
    "    \n",
    "    with open(cache_path, \"wb\") as f:\n",
    "        pickle.dump(cluster, f)\n",
    "    \n",
    "    return cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x1a25bca7b8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1584x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "K = 512\n",
    "codebook = get_codewords(SubsetDataset, uniq_tracks, n_clusters=K, max_iter=3, random_state=98765)\n",
    "plt.figure(figsize=(22, 4))\n",
    "plt.imshow(codebook.cluster_centers_.T, cmap=\"PuOr_r\", aspect=\"auto\", interpolation=\"nearest\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Build a bag-of-word representation of each song\n",
    "\n",
    "Each song, $s_i$, is a $K$-dimensional vector, where element $j$ menas the number of times the $j$th centroid has been matched. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_idx_to_song_id_mapping():\n",
    "    idx_to_song_id_mapping = {}\n",
    "    song_id_to_idx_mapping = {}\n",
    "    running_idx = 0\n",
    "    for track_i, track_id in enumerate(uniq_tracks):\n",
    "        for song_id in track_id_to_song_id[track_id]:\n",
    "            idx_to_song_id_mapping[running_idx] = song_id\n",
    "            song_id_to_idx_mapping[song_id] = running_idx\n",
    "            running_idx += 1\n",
    "    return idx_to_song_id_mapping, song_id_to_idx_mapping\n",
    "\n",
    "idx_to_song_id_mapping, song_id_to_idx_mapping = build_idx_to_song_id_mapping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vq = VectorQuantizer(clusterer=codebook)\n",
    "vq.center_norms_ = 0.5 * (vq.clusterer.cluster_centers_ ** 2).sum(axis=1)\n",
    "vq.components_ = vq.clusterer.cluster_centers_\n",
    "\n",
    "song_bow = np.zeros((len(song_id_to_idx_mapping), K))\n",
    "\n",
    "def quantize_and_save(vq, K, msd_data_root, track_id, song_id, song_idx=0):\n",
    "    hist_dir = os.path.join(\"data\", \"vq_hist\", \"/\".join(track_id[2:5]))\n",
    "    if not os.path.exists(hist_dir):\n",
    "        os.makedirs(hist_dir)\n",
    "\n",
    "    vq_path = os.path.join(hist_dir, track_id + '_' + song_id + '_K%d' % K)\n",
    "    if os.path.exists(os.path.join(vq_path) + '.npy'):\n",
    "        return np.load(os.path.join(vq_path) + '.npy')\n",
    "    \n",
    "    track_dir = os.path.join(msd_data_root, '/'.join(track_id[2:5]), track_id + '.h5')\n",
    "    h5 = hdf5_getters.open_h5_file_read(track_dir)\n",
    "    timbre = hdf5_getters.get_segments_timbre(h5, song_idx)\n",
    "    h5.close()\n",
    "\n",
    "    vq_hist = vq.transform(timbre).sum(axis=0).astype(np.int16)\n",
    "    np.save(os.path.join(hist_dir, track_id + '_' + song_id + '_K%d' % K), vq_hist)\n",
    "    return vq_hist\n",
    "\n",
    "\n",
    "for track_id in uniq_tracks:\n",
    "    for song_idx, song_id in enumerate(track_id_to_song_id[track_id]):\n",
    "        song_bow[song_id_to_idx_mapping[song_id]] = quantize_and_save(vq, K, SubsetDataset.MSD_DATA_DIR, track_id, song_id, song_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(song_id_to_idx_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Get Latent Factors for Users\n",
    "\n",
    "Source: [Deep Content-based Music Recommendation](https://papers.nips.cc/paper/5004-deep-content-based-music-recommendation.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Build user-item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_uniq_users(profile_path, cache_dir=os.path.join('.', 'data', 'cache')):\n",
    "    users = set()\n",
    "    profile_name = os.path.basename(profile_path).split('.')\n",
    "    if len(profile_name) > 1:\n",
    "        profile_name = profile_name[:-1]\n",
    "    cache_path = os.path.join(cache_dir, f'users-{profile_name}.json')\n",
    "\n",
    "    if os.path.exists(cache_path):\n",
    "        with open(cache_path, 'r') as f:\n",
    "            return json.load(f)\n",
    "\n",
    "    with open(profile_path, 'r') as f:\n",
    "        for (count, line) in enumerate(f):\n",
    "            user_id = line.strip().split('\\t')[0]\n",
    "            users.add(user_id)\n",
    "            if count % 100000 == 0:\n",
    "                print(f'{count} listening history processed')\n",
    "\n",
    "    if not os.path.exists(cache_dir):\n",
    "        os.makedirs(cache_dir)\n",
    "    \n",
    "    users = list(users)\n",
    "    with open(cache_path, 'w') as f:\n",
    "        json.dump(users, f)\n",
    "    \n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uniq_users = get_uniq_users(TasteProfileDataset.TPD_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uniq_user_to_idx = {user_id: i for i, user_id in enumerate(uniq_users)}\n",
    "idx_to_uniq_user = {i: user_id for i, user_id in enumerate(uniq_users)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "uniq_track_to_idx = {track_id: i for i, track_id in enumerate(uniq_tracks)}\n",
    "idx_to_uniq_track = {i: track_id for i, track_id in enumerate(uniq_tracks)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Songs: 3688\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from lib import song_subset\n",
    "importlib.reload(song_subset)\n",
    "\n",
    "train_tpd = TasteProfileDataset.TPD_TRAIN_PATH\n",
    "val_msc_visible = MSDChallengeDataset.MSDC_EVAL_VISIBLE_PATH\n",
    "val_msc_hidden = MSDChallengeDataset.MSDC_EVAL_HIDDEN_PATH\n",
    "test_msc_visible = MSDChallengeDataset.MSDC_TEST_VISIBLE_PATH\n",
    "test_msc_hidden = MSDChallengeDataset.MSDC_TEST_HIDDEN_PATH\n",
    "\n",
    "valid_songs = song_subset.get_trainable_songs([train_tpd, val_msc_visible, val_msc_hidden, test_msc_visible, test_msc_hidden])\n",
    "valid_songs &= set(song_id_to_track_id.keys())\n",
    "\n",
    "print('Total Songs:', len(valid_songs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       SOFXNQP12AB0184F1A\n",
       "1       SOVWTMN12A6D4F8ACF\n",
       "2       SONLXKV12A8C13CD49\n",
       "3       SOGAALD12A6D4F58F2\n",
       "4       SORSQRR12A8C13A20D\n",
       "               ...        \n",
       "3683    SOOIPTF12A8C139366\n",
       "3684    SOUHVMV12A58A7C4D9\n",
       "3685    SODWQCV12A6701F288\n",
       "3686    SOADDVU12A8AE47512\n",
       "3687    SODKZHX12AB0180CC7\n",
       "Length: 3688, dtype: category\n",
       "Categories (3688, object): [SOAAAQN12AB01856D3, SOAAEHR12A6D4FB060, SOAAFUV12AB018831D, SOAANKE12A8C13CF5C, ..., SOZYZDZ12AB01873CA, SOZZPYH12AB0187578, SOZZQBH12A6D4FAFD8, SOZZVMW12AB0183B52]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "valid_song_list = list(valid_songs)\n",
    "valid_song_list_i_to_song = {v: i for i, v in enumerate(valid_song_list)}\n",
    "song_categories = pd.Series(valid_song_list, dtype=\"category\")\n",
    "song_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_play_array(line, transform_cui=lambda x: x if x > 0 else 0):\n",
    "    user_id, song_id, play_count = line.strip().split(\"\\t\")\n",
    "    if song_id not in song_id_to_track_id:\n",
    "        return None\n",
    "\n",
    "    return [user_id, song_id, transform_cui(int(play_count))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "\n",
    "def build_user_item_matrix(profile_path, song_categories=None, song_to_idx_map=None, transform_cui=lambda x: x if x > 0 else 0):\n",
    "    user_to_item_plays = []\n",
    "    uniq_users = set()\n",
    "    \n",
    "    successful, not_in_song_mapping, not_in_track_mapping = 0, 0, 0\n",
    "    tracks_added = set()\n",
    "    with open(profile_path, 'r') as f:\n",
    "        for (count, line) in enumerate(f):\n",
    "            if count % 100000 == 0:\n",
    "                print(f\"{count} listening history processed\")\n",
    "                \n",
    "            user_play = get_user_play_array(line, transform_cui)\n",
    "            \n",
    "            if user_play is None:\n",
    "                continue\n",
    "                \n",
    "            uniq_users.add(user_play[0])\n",
    "            user_to_item_plays.append(user_play)\n",
    "            \n",
    "            successful += 1\n",
    "    \n",
    "    print(f\"Successful: {successful}\")\n",
    "    print(f\"Not in song mapping: {not_in_song_mapping}\")\n",
    "    print(f\"Not in track mapping: {not_in_track_mapping}\")\n",
    "    \n",
    "    user_to_item_plays = pd.DataFrame(user_to_item_plays, columns=['user_id', 'track_id', 'plays'])\n",
    "    user_to_item_plays['user_id'] = user_to_item_plays['user_id'].astype('category')\n",
    "    user_to_item_plays['track_id'] = user_to_item_plays['track_id'].astype('category')\n",
    "    \n",
    "    if song_categories is not None and song_to_idx_map is not None:\n",
    "        user_to_item_plays['track_id'].cat = song_categories\n",
    "        user_to_item_plays['track_id'] = user_to_item_plays['track_id'].map(song_to_idx_map)\n",
    "\n",
    "#         user_item = coo_matrix((user_to_item_plays['plays'], (user_to_item_plays['user_id'].cat.codes, user_to_item_plays['track_id'])), shape=(user_to_item_plays['user_id'].value_counts().count(), len(song_categories)))\n",
    "        user_item = coo_matrix((user_to_item_plays['plays'], (user_to_item_plays['user_id'].cat.codes, user_to_item_plays['track_id'])), shape=(len(uniq_users), len(song_categories)))\n",
    "    else:\n",
    "        user_item = coo_matrix((user_to_item_plays['plays'], (user_to_item_plays['user_id'].cat.codes, user_to_item_plays['track_id'].cat.codes)))\n",
    "    \n",
    "    return user_item.tocsr(), user_to_item_plays['user_id'].cat.categories, user_to_item_plays['track_id'].cat.categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 listening history processed\n",
      "100000 listening history processed\n",
      "200000 listening history processed\n",
      "300000 listening history processed\n",
      "400000 listening history processed\n",
      "500000 listening history processed\n",
      "600000 listening history processed\n",
      "700000 listening history processed\n",
      "800000 listening history processed\n",
      "900000 listening history processed\n",
      "1000000 listening history processed\n",
      "1100000 listening history processed\n",
      "1200000 listening history processed\n",
      "1300000 listening history processed\n",
      "1400000 listening history processed\n",
      "1500000 listening history processed\n",
      "1600000 listening history processed\n",
      "1700000 listening history processed\n",
      "1800000 listening history processed\n",
      "1900000 listening history processed\n",
      "2000000 listening history processed\n",
      "2100000 listening history processed\n",
      "2200000 listening history processed\n",
      "2300000 listening history processed\n",
      "2400000 listening history processed\n",
      "2500000 listening history processed\n",
      "2600000 listening history processed\n",
      "2700000 listening history processed\n",
      "2800000 listening history processed\n",
      "2900000 listening history processed\n",
      "3000000 listening history processed\n",
      "3100000 listening history processed\n",
      "3200000 listening history processed\n",
      "3300000 listening history processed\n",
      "3400000 listening history processed\n",
      "3500000 listening history processed\n",
      "3600000 listening history processed\n",
      "3700000 listening history processed\n",
      "3800000 listening history processed\n",
      "3900000 listening history processed\n",
      "4000000 listening history processed\n",
      "4100000 listening history processed\n",
      "4200000 listening history processed\n",
      "4300000 listening history processed\n",
      "4400000 listening history processed\n",
      "4500000 listening history processed\n",
      "4600000 listening history processed\n",
      "4700000 listening history processed\n",
      "4800000 listening history processed\n",
      "4900000 listening history processed\n",
      "5000000 listening history processed\n",
      "5100000 listening history processed\n",
      "5200000 listening history processed\n",
      "5300000 listening history processed\n",
      "5400000 listening history processed\n",
      "5500000 listening history processed\n",
      "5600000 listening history processed\n",
      "5700000 listening history processed\n",
      "5800000 listening history processed\n",
      "5900000 listening history processed\n",
      "6000000 listening history processed\n",
      "6100000 listening history processed\n",
      "6200000 listening history processed\n",
      "6300000 listening history processed\n",
      "6400000 listening history processed\n",
      "6500000 listening history processed\n",
      "6600000 listening history processed\n",
      "6700000 listening history processed\n",
      "6800000 listening history processed\n",
      "6900000 listening history processed\n",
      "7000000 listening history processed\n",
      "7100000 listening history processed\n",
      "7200000 listening history processed\n",
      "7300000 listening history processed\n",
      "7400000 listening history processed\n",
      "7500000 listening history processed\n",
      "7600000 listening history processed\n",
      "7700000 listening history processed\n",
      "7800000 listening history processed\n",
      "7900000 listening history processed\n",
      "8000000 listening history processed\n",
      "8100000 listening history processed\n",
      "8200000 listening history processed\n",
      "8300000 listening history processed\n",
      "8400000 listening history processed\n",
      "8500000 listening history processed\n",
      "8600000 listening history processed\n",
      "8700000 listening history processed\n",
      "8800000 listening history processed\n",
      "8900000 listening history processed\n",
      "9000000 listening history processed\n",
      "9100000 listening history processed\n",
      "9200000 listening history processed\n",
      "9300000 listening history processed\n",
      "9400000 listening history processed\n",
      "9500000 listening history processed\n",
      "9600000 listening history processed\n",
      "9700000 listening history processed\n",
      "9800000 listening history processed\n",
      "9900000 listening history processed\n",
      "10000000 listening history processed\n",
      "10100000 listening history processed\n",
      "10200000 listening history processed\n",
      "10300000 listening history processed\n",
      "10400000 listening history processed\n",
      "10500000 listening history processed\n",
      "10600000 listening history processed\n",
      "10700000 listening history processed\n",
      "10800000 listening history processed\n",
      "10900000 listening history processed\n",
      "11000000 listening history processed\n",
      "11100000 listening history processed\n",
      "11200000 listening history processed\n",
      "11300000 listening history processed\n",
      "11400000 listening history processed\n",
      "11500000 listening history processed\n",
      "11600000 listening history processed\n",
      "11700000 listening history processed\n",
      "11800000 listening history processed\n",
      "11900000 listening history processed\n",
      "12000000 listening history processed\n",
      "12100000 listening history processed\n",
      "12200000 listening history processed\n",
      "12300000 listening history processed\n",
      "12400000 listening history processed\n",
      "12500000 listening history processed\n",
      "12600000 listening history processed\n",
      "12700000 listening history processed\n",
      "12800000 listening history processed\n",
      "12900000 listening history processed\n",
      "13000000 listening history processed\n",
      "13100000 listening history processed\n",
      "13200000 listening history processed\n",
      "13300000 listening history processed\n",
      "13400000 listening history processed\n",
      "13500000 listening history processed\n",
      "13600000 listening history processed\n",
      "13700000 listening history processed\n",
      "13800000 listening history processed\n",
      "13900000 listening history processed\n",
      "14000000 listening history processed\n",
      "14100000 listening history processed\n",
      "14200000 listening history processed\n",
      "14300000 listening history processed\n",
      "14400000 listening history processed\n",
      "14500000 listening history processed\n",
      "14600000 listening history processed\n",
      "14700000 listening history processed\n",
      "14800000 listening history processed\n",
      "14900000 listening history processed\n",
      "15000000 listening history processed\n",
      "15100000 listening history processed\n",
      "15200000 listening history processed\n",
      "15300000 listening history processed\n",
      "15400000 listening history processed\n",
      "15500000 listening history processed\n",
      "15600000 listening history processed\n",
      "15700000 listening history processed\n",
      "15800000 listening history processed\n",
      "15900000 listening history processed\n",
      "16000000 listening history processed\n",
      "16100000 listening history processed\n",
      "16200000 listening history processed\n",
      "16300000 listening history processed\n",
      "16400000 listening history processed\n",
      "16500000 listening history processed\n",
      "16600000 listening history processed\n",
      "16700000 listening history processed\n",
      "16800000 listening history processed\n",
      "16900000 listening history processed\n",
      "17000000 listening history processed\n",
      "17100000 listening history processed\n",
      "17200000 listening history processed\n",
      "17300000 listening history processed\n",
      "17400000 listening history processed\n",
      "17500000 listening history processed\n",
      "17600000 listening history processed\n",
      "17700000 listening history processed\n",
      "17800000 listening history processed\n",
      "17900000 listening history processed\n",
      "18000000 listening history processed\n",
      "18100000 listening history processed\n",
      "18200000 listening history processed\n",
      "18300000 listening history processed\n",
      "18400000 listening history processed\n",
      "18500000 listening history processed\n",
      "18600000 listening history processed\n",
      "18700000 listening history processed\n",
      "18800000 listening history processed\n",
      "18900000 listening history processed\n",
      "19000000 listening history processed\n",
      "19100000 listening history processed\n",
      "19200000 listening history processed\n",
      "19300000 listening history processed\n",
      "19400000 listening history processed\n",
      "19500000 listening history processed\n",
      "19600000 listening history processed\n",
      "19700000 listening history processed\n",
      "19800000 listening history processed\n",
      "19900000 listening history processed\n",
      "20000000 listening history processed\n",
      "20100000 listening history processed\n",
      "20200000 listening history processed\n",
      "20300000 listening history processed\n",
      "20400000 listening history processed\n",
      "20500000 listening history processed\n",
      "20600000 listening history processed\n",
      "20700000 listening history processed\n",
      "20800000 listening history processed\n",
      "20900000 listening history processed\n",
      "21000000 listening history processed\n",
      "21100000 listening history processed\n",
      "21200000 listening history processed\n",
      "21300000 listening history processed\n",
      "21400000 listening history processed\n",
      "21500000 listening history processed\n",
      "21600000 listening history processed\n",
      "21700000 listening history processed\n",
      "21800000 listening history processed\n",
      "21900000 listening history processed\n",
      "22000000 listening history processed\n",
      "22100000 listening history processed\n",
      "22200000 listening history processed\n",
      "22300000 listening history processed\n",
      "22400000 listening history processed\n",
      "22500000 listening history processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22600000 listening history processed\n",
      "22700000 listening history processed\n",
      "22800000 listening history processed\n",
      "22900000 listening history processed\n",
      "23000000 listening history processed\n",
      "23100000 listening history processed\n",
      "23200000 listening history processed\n",
      "23300000 listening history processed\n",
      "23400000 listening history processed\n",
      "23500000 listening history processed\n",
      "23600000 listening history processed\n",
      "23700000 listening history processed\n",
      "23800000 listening history processed\n",
      "23900000 listening history processed\n",
      "24000000 listening history processed\n",
      "24100000 listening history processed\n",
      "24200000 listening history processed\n",
      "24300000 listening history processed\n",
      "24400000 listening history processed\n",
      "24500000 listening history processed\n",
      "24600000 listening history processed\n",
      "24700000 listening history processed\n",
      "24800000 listening history processed\n",
      "24900000 listening history processed\n",
      "25000000 listening history processed\n",
      "25100000 listening history processed\n",
      "25200000 listening history processed\n",
      "25300000 listening history processed\n",
      "25400000 listening history processed\n",
      "25500000 listening history processed\n",
      "25600000 listening history processed\n",
      "25700000 listening history processed\n",
      "25800000 listening history processed\n",
      "25900000 listening history processed\n",
      "26000000 listening history processed\n",
      "26100000 listening history processed\n",
      "26200000 listening history processed\n",
      "26300000 listening history processed\n",
      "26400000 listening history processed\n",
      "26500000 listening history processed\n",
      "26600000 listening history processed\n",
      "26700000 listening history processed\n",
      "26800000 listening history processed\n",
      "26900000 listening history processed\n",
      "27000000 listening history processed\n",
      "27100000 listening history processed\n",
      "27200000 listening history processed\n",
      "27300000 listening history processed\n",
      "27400000 listening history processed\n",
      "27500000 listening history processed\n",
      "27600000 listening history processed\n",
      "27700000 listening history processed\n",
      "27800000 listening history processed\n",
      "27900000 listening history processed\n",
      "28000000 listening history processed\n",
      "28100000 listening history processed\n",
      "28200000 listening history processed\n",
      "28300000 listening history processed\n",
      "28400000 listening history processed\n",
      "28500000 listening history processed\n",
      "28600000 listening history processed\n",
      "28700000 listening history processed\n",
      "28800000 listening history processed\n",
      "28900000 listening history processed\n",
      "29000000 listening history processed\n",
      "29100000 listening history processed\n",
      "29200000 listening history processed\n",
      "29300000 listening history processed\n",
      "29400000 listening history processed\n",
      "29500000 listening history processed\n",
      "29600000 listening history processed\n",
      "29700000 listening history processed\n",
      "29800000 listening history processed\n",
      "29900000 listening history processed\n",
      "30000000 listening history processed\n",
      "30100000 listening history processed\n",
      "30200000 listening history processed\n",
      "30300000 listening history processed\n",
      "30400000 listening history processed\n",
      "30500000 listening history processed\n",
      "30600000 listening history processed\n",
      "30700000 listening history processed\n",
      "30800000 listening history processed\n",
      "30900000 listening history processed\n",
      "31000000 listening history processed\n",
      "31100000 listening history processed\n",
      "31200000 listening history processed\n",
      "31300000 listening history processed\n",
      "31400000 listening history processed\n",
      "31500000 listening history processed\n",
      "31600000 listening history processed\n",
      "31700000 listening history processed\n",
      "31800000 listening history processed\n",
      "31900000 listening history processed\n",
      "32000000 listening history processed\n",
      "32100000 listening history processed\n",
      "32200000 listening history processed\n",
      "32300000 listening history processed\n",
      "32400000 listening history processed\n",
      "32500000 listening history processed\n",
      "32600000 listening history processed\n",
      "32700000 listening history processed\n",
      "32800000 listening history processed\n",
      "32900000 listening history processed\n",
      "33000000 listening history processed\n",
      "33100000 listening history processed\n",
      "33200000 listening history processed\n",
      "33300000 listening history processed\n",
      "33400000 listening history processed\n",
      "33500000 listening history processed\n",
      "33600000 listening history processed\n",
      "33700000 listening history processed\n",
      "33800000 listening history processed\n",
      "33900000 listening history processed\n",
      "34000000 listening history processed\n",
      "34100000 listening history processed\n",
      "34200000 listening history processed\n",
      "34300000 listening history processed\n",
      "34400000 listening history processed\n",
      "34500000 listening history processed\n",
      "34600000 listening history processed\n",
      "34700000 listening history processed\n",
      "34800000 listening history processed\n",
      "34900000 listening history processed\n",
      "35000000 listening history processed\n",
      "35100000 listening history processed\n",
      "35200000 listening history processed\n",
      "35300000 listening history processed\n",
      "35400000 listening history processed\n",
      "35500000 listening history processed\n",
      "35600000 listening history processed\n",
      "35700000 listening history processed\n",
      "35800000 listening history processed\n",
      "35900000 listening history processed\n",
      "36000000 listening history processed\n",
      "36100000 listening history processed\n",
      "36200000 listening history processed\n",
      "36300000 listening history processed\n",
      "36400000 listening history processed\n",
      "36500000 listening history processed\n",
      "36600000 listening history processed\n",
      "36700000 listening history processed\n",
      "36800000 listening history processed\n",
      "36900000 listening history processed\n",
      "37000000 listening history processed\n",
      "37100000 listening history processed\n",
      "37200000 listening history processed\n",
      "37300000 listening history processed\n",
      "37400000 listening history processed\n",
      "37500000 listening history processed\n",
      "37600000 listening history processed\n",
      "37700000 listening history processed\n",
      "37800000 listening history processed\n",
      "37900000 listening history processed\n",
      "38000000 listening history processed\n",
      "38100000 listening history processed\n",
      "38200000 listening history processed\n",
      "38300000 listening history processed\n",
      "38400000 listening history processed\n",
      "38500000 listening history processed\n",
      "38600000 listening history processed\n",
      "38700000 listening history processed\n",
      "38800000 listening history processed\n",
      "38900000 listening history processed\n",
      "39000000 listening history processed\n",
      "39100000 listening history processed\n",
      "39200000 listening history processed\n",
      "39300000 listening history processed\n",
      "39400000 listening history processed\n",
      "39500000 listening history processed\n",
      "39600000 listening history processed\n",
      "39700000 listening history processed\n",
      "39800000 listening history processed\n",
      "39900000 listening history processed\n",
      "40000000 listening history processed\n",
      "40100000 listening history processed\n",
      "40200000 listening history processed\n",
      "40300000 listening history processed\n",
      "40400000 listening history processed\n",
      "40500000 listening history processed\n",
      "40600000 listening history processed\n",
      "40700000 listening history processed\n",
      "40800000 listening history processed\n",
      "40900000 listening history processed\n",
      "41000000 listening history processed\n",
      "41100000 listening history processed\n",
      "41200000 listening history processed\n",
      "41300000 listening history processed\n",
      "41400000 listening history processed\n",
      "41500000 listening history processed\n",
      "41600000 listening history processed\n",
      "41700000 listening history processed\n",
      "41800000 listening history processed\n",
      "41900000 listening history processed\n",
      "42000000 listening history processed\n",
      "42100000 listening history processed\n",
      "42200000 listening history processed\n",
      "42300000 listening history processed\n",
      "42400000 listening history processed\n",
      "42500000 listening history processed\n",
      "42600000 listening history processed\n",
      "42700000 listening history processed\n",
      "42800000 listening history processed\n",
      "42900000 listening history processed\n",
      "43000000 listening history processed\n",
      "43100000 listening history processed\n",
      "43200000 listening history processed\n",
      "43300000 listening history processed\n",
      "43400000 listening history processed\n",
      "43500000 listening history processed\n",
      "43600000 listening history processed\n",
      "43700000 listening history processed\n",
      "43800000 listening history processed\n",
      "43900000 listening history processed\n",
      "44000000 listening history processed\n",
      "44100000 listening history processed\n",
      "44200000 listening history processed\n",
      "44300000 listening history processed\n",
      "44400000 listening history processed\n",
      "44500000 listening history processed\n",
      "44600000 listening history processed\n",
      "44700000 listening history processed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44800000 listening history processed\n",
      "44900000 listening history processed\n",
      "45000000 listening history processed\n",
      "45100000 listening history processed\n",
      "45200000 listening history processed\n",
      "45300000 listening history processed\n",
      "45400000 listening history processed\n",
      "45500000 listening history processed\n",
      "45600000 listening history processed\n",
      "45700000 listening history processed\n",
      "45800000 listening history processed\n",
      "45900000 listening history processed\n",
      "46000000 listening history processed\n",
      "46100000 listening history processed\n",
      "46200000 listening history processed\n",
      "46300000 listening history processed\n",
      "46400000 listening history processed\n",
      "46500000 listening history processed\n",
      "46600000 listening history processed\n",
      "46700000 listening history processed\n",
      "46800000 listening history processed\n",
      "46900000 listening history processed\n",
      "47000000 listening history processed\n",
      "47100000 listening history processed\n",
      "47200000 listening history processed\n",
      "47300000 listening history processed\n",
      "47400000 listening history processed\n",
      "47500000 listening history processed\n",
      "47600000 listening history processed\n",
      "47700000 listening history processed\n",
      "47800000 listening history processed\n",
      "47900000 listening history processed\n",
      "48000000 listening history processed\n",
      "48100000 listening history processed\n",
      "48200000 listening history processed\n",
      "48300000 listening history processed\n",
      "Successful: 772661\n",
      "Not in song mapping: 0\n",
      "Not in track mapping: 0\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def transform_cui(play_count):\n",
    "    if play_count == 0:\n",
    "        return 0\n",
    "    \n",
    "    alpha = 1\n",
    "    epsilon = 0.01\n",
    "    return 1 + alpha * math.log(1 + play_count / epsilon)\n",
    "\n",
    "user_item_matrix = build_user_item_matrix(TasteProfileDataset.TPD_TRAIN_PATH, song_categories, valid_song_list_i_to_song, transform_cui)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(418252, 3688)\n"
     ]
    }
   ],
   "source": [
    "print(user_item_matrix.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc4d499903d3402bb166d66713cb039a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import implicit\n",
    "\n",
    "model = implicit.als.AlternatingLeastSquares(factors=50)\n",
    "model.fit(item_users=user_item_matrix.T)\n",
    "\n",
    "train_user_factors = model.user_factors.copy()\n",
    "train_item_factors = model.item_factors.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3688, 50)\n"
     ]
    }
   ],
   "source": [
    "print(model.item_factors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Evaluation Data\n",
    "\n",
    "We need to discard recommended songs that are not actually in the (sub-)dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Predictions with User-Item Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 listening history processed\n",
      "100000 listening history processed\n",
      "Successful: 2089\n",
      "Not in song mapping: 0\n",
      "Not in track mapping: 0\n"
     ]
    }
   ],
   "source": [
    "eval_user_item_matrix, user_cat, item_cat = build_user_item_matrix(MSDChallengeDataset.MSDC_EVAL_VISIBLE_PATH, song_categories, valid_song_list_i_to_song, transform_cui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73bf8f30f7fa40749c88796ad7e00e94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1780), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations = model.recommend_all(eval_user_item_matrix, recalculate_user=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_songs(profile_path):\n",
    "    songs = {}\n",
    "    \n",
    "    with open(profile_path, 'r') as f:\n",
    "        for (count, line) in enumerate(f):\n",
    "            user_id, song_id, _ = line.strip().split(\"\\t\")\n",
    "            \n",
    "            if user_id not in songs:\n",
    "                songs[user_id] = set([song_id])\n",
    "            else:\n",
    "                songs[user_id].add(song_id)\n",
    "    \n",
    "    return songs\n",
    "\n",
    "\n",
    "def build_predicted_and_actual_songs(predicted_user_songs, actual_user_songs):\n",
    "    predicted_songs = []\n",
    "    actual_songs = []\n",
    "    \n",
    "    for user_i, user_items in enumerate(recommendations):\n",
    "        predicted_songs_for_user = []\n",
    "        for item in user_items:\n",
    "            predicted_songs_for_user += [song_categories[item]]\n",
    "        predicted_songs += [predicted_songs_for_user]\n",
    "        actual_songs += [list(actual_user_songs[user_cat[user_i]])]\n",
    "    \n",
    "    return predicted_songs, actual_songs\n",
    "\n",
    "\n",
    "actual_user_songs = get_user_songs(MSDChallengeDataset.MSDC_EVAL_HIDDEN_PATH)\n",
    "predicted_songs, actual_songs = build_predicted_and_actual_songs(recommendations, actual_user_songs)\n",
    "\n",
    "\n",
    "eval_user_factors = model.user_factors.copy()\n",
    "eval_item_factors = model.item_factors.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015119047619047618"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib import metrics\n",
    "\n",
    "metrics.mean_average_precision(predicted_songs, actual_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 listening history processed\n",
      "100000 listening history processed\n",
      "200000 listening history processed\n",
      "300000 listening history processed\n",
      "400000 listening history processed\n",
      "500000 listening history processed\n",
      "600000 listening history processed\n",
      "700000 listening history processed\n",
      "800000 listening history processed\n",
      "900000 listening history processed\n",
      "1000000 listening history processed\n",
      "1100000 listening history processed\n",
      "1200000 listening history processed\n",
      "1300000 listening history processed\n",
      "Successful: 21039\n",
      "Not in song mapping: 0\n",
      "Not in track mapping: 0\n"
     ]
    }
   ],
   "source": [
    "test_user_item_matrix, user_cat, item_cat = build_user_item_matrix(MSDChallengeDataset.MSDC_TEST_VISIBLE_PATH, song_categories, valid_song_list_i_to_song, transform_cui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3bba26aab0d41c38d5e2dc169c0a181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=18042), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recommendations = model.recommend_all(test_user_item_matrix, recalculate_user=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011603920657794952"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_user_songs = get_user_songs(MSDChallengeDataset.MSDC_TEST_HIDDEN_PATH)\n",
    "predicted_songs, actual_songs = build_predicted_and_actual_songs(recommendations, actual_user_songs)\n",
    "\n",
    "metrics.mean_average_precision(predicted_songs, actual_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Using LSTM to Make Predictions\n",
    "\n",
    "The idea is to predict the latent factors from the audio features (framed as a regression problem) to make \n",
    "predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from torch import randperm\n",
    "from torch._utils import _accumulate\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class MillionSongDataset__Preloaded(Dataset):\n",
    "    \"\"\"MillionSongDataset__Preloaded is for the notebook version where\n",
    "    much of the data is already in memory.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, song_id_to_track_id, valid_song_list, latent_factors, ConstantClass):\n",
    "        self.song_id_to_track_id = song_id_to_track_id\n",
    "        self.valid_song_list = valid_song_list\n",
    "        self.ConstantClass = ConstantClass\n",
    "        self.latent_factors = latent_factors\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.valid_song_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        song_id = self.valid_song_list[idx]\n",
    "        track_id = self.song_id_to_track_id[song_id]\n",
    "        track_dir = os.path.join(self.ConstantClass.MSD_DATA_DIR, '/'.join(track_id[2:5]), track_id + '.h5')\n",
    "        h5 = hdf5_getters.open_h5_file_read(track_dir)\n",
    "        \n",
    "        for i in range(hdf5_getters.get_num_songs(h5)):\n",
    "            sid = hdf5_getters.get_song_id(h5, i).decode('utf-8')\n",
    "            if sid != song_id:\n",
    "                continue\n",
    "            timbre = torch.Tensor(hdf5_getters.get_segments_timbre(h5, i))\n",
    "        \n",
    "        h5.close()\n",
    "\n",
    "        return timbre, torch.Tensor(self.latent_factors[idx])\n",
    "\n",
    "\n",
    "class Subset(Dataset):\n",
    "    \"\"\"\n",
    "    Subset of a dataset at specified indices.\n",
    "\n",
    "    Arguments:\n",
    "        dataset (Dataset): The whole Dataset\n",
    "        indices (sequence): Indices in the whole set selected for subset\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset, indices):\n",
    "        self.dataset = dataset\n",
    "        self.indices = indices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[self.indices[idx]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    \n",
    "def random_split(dataset, lengths):\n",
    "    r\"\"\"\n",
    "    Randomly split a dataset into non-overlapping new datasets of given lengths.\n",
    "\n",
    "    Arguments:\n",
    "        dataset (Dataset): Dataset to be split\n",
    "        lengths (sequence): lengths of splits to be produced\n",
    "    \"\"\"\n",
    "    if sum(lengths) != len(dataset):\n",
    "        raise ValueError(\"Sum of input lengths does not equal the length of the input dataset!\")\n",
    "\n",
    "    indices = randperm(sum(lengths)).tolist()\n",
    "    return [Subset(dataset, indices[offset - length:offset]) for offset, length in zip(_accumulate(lengths), lengths)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "class LSTMToLatentFactor(nn.Module):\n",
    "    def __init__(self, input_dim=12, hidden_dim=72, output_dim=50):\n",
    "        super(LSTMToLatentFactor, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, batch):\n",
    "        sequences, sequence_lengths, _ = batch\n",
    "        sequences_packed = pack_padded_sequence(sequences, sequence_lengths, batch_first=True)\n",
    "        h0 = torch.zeros([1, sequences.shape[0], self.hidden_dim], dtype=torch.float)\n",
    "        c0 = torch.zeros([1, sequences.shape[0], self.hidden_dim], dtype=torch.float)\n",
    "        lstm_out, (h, c) = self.lstm(sequences_packed, (h0, c0))\n",
    "        final_h = h[-1]\n",
    "        regressor_out = self.linear(final_h.view(sequences.shape[0], -1))\n",
    "        return regressor_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    \"\"\"Because songs have different lengths, let's pad them to uniform lengths.\"\"\"\n",
    "    # https://www.codefull.net/2018/11/use-pytorchs-dataloader-with-variable-length-sequences-for-lstm-gru/\n",
    "    sorted_pairs = sorted(batch, key=lambda x: x[0].shape[0], reverse=True)\n",
    "    sequences = [torch.Tensor(x[0]) for x in sorted_pairs]\n",
    "    sequences_padded = nn.utils.rnn.pad_sequence(sequences, batch_first=True)\n",
    "    lengths = torch.Tensor([sequence.shape[0] for sequence in sequences])\n",
    "    latent_f = torch.FloatTensor([x[1].numpy() for x in sorted_pairs])\n",
    "    return sequences_padded, lengths, latent_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://nusit.nus.edu.sg/technus/hpc/deep-learning-best-practices-checkpointing-deep-learning-model-training/\n",
    "\n",
    "import shutil\n",
    "\n",
    "\n",
    "def has_checkpoint(checkpoint, is_best=False):\n",
    "    if is_best:\n",
    "        filepath = os.path.join(checkpoint, 'best.pth.tar')\n",
    "    else:\n",
    "        filepath = os.path.join(checkpoint, 'last.pth.tar')\n",
    "    return os.path.exists(filepath)\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, checkpoint):\n",
    "    \"\"\"Saves model and training parameters at checkpoint + 'last.pth.tar'. If is_best==True, also saves\n",
    "    checkpoint + 'best.pth.tar'\n",
    "    Args:\n",
    "        state: (dict) contains model's state_dict, may contain other keys such as epoch, optimizer state_dict\n",
    "        is_best: (bool) True if it is the best model seen till now\n",
    "        checkpoint: (string) folder where parameters are to be saved\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(checkpoint, 'last.pth.tar')\n",
    "    if not os.path.exists(checkpoint):\n",
    "        print(\"Checkpoint directory does not exist. Making directory {}\".format(checkpoint))\n",
    "        os.makedirs(checkpoint)\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(checkpoint, 'best.pth.tar'))\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint, model, optimizer=None):\n",
    "    \"\"\"Loads model parameters (state_dict) from file_path. If optimizer is provided, loads state_dict of\n",
    "    optimizer assuming it is present in checkpoint.\n",
    "    Args:\n",
    "        checkpoint: (string) filename which needs to be loaded\n",
    "        model: (torch.nn.Module) model for which the parameters are loaded\n",
    "        optimizer: (torch.optim) optional: resume optimizer from checkpoint\n",
    "    \"\"\"\n",
    "    if not os.path.exists(checkpoint):\n",
    "        raise(\"File doesn't exist {}\".format(checkpoint))\n",
    "    checkpoint = torch.load(checkpoint)\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "    if optimizer:\n",
    "        optimizer.load_state_dict(checkpoint['optim_dict'])\n",
    "\n",
    "    return checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid_songs = song_subset.get_trainable_songs([train_tpd])\n",
    "train_valid_songs &= set(song_id_to_track_id.keys())\n",
    "train_valid_song_list = list(train_valid_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from best\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "msd = MillionSongDataset__Preloaded(song_id_to_track_id, train_valid_song_list, train_item_factors, SubsetDataset)\n",
    "lstm_model = LSTMToLatentFactor().to(device)\n",
    "train_data_count = int(len(train_valid_song_list) * 0.8)\n",
    "valid_data_count = int(len(train_valid_song_list) * 0.1)\n",
    "test_data_count = len(train_valid_song_list) - train_data_count - valid_data_count\n",
    "train_dataset, valid_dataset, test_dataset = random_split(msd, [train_data_count, valid_data_count, test_data_count])\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                batch_size=100,\n",
    "                                                collate_fn=collate_fn)\n",
    "valid_data_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                                batch_size=100,\n",
    "                                                collate_fn=collate_fn)\n",
    "\n",
    "best_dev_mae = -1\n",
    "\n",
    "learning_rate = 0.01\n",
    "epochs = 1\n",
    "save_every = 50\n",
    "eval_every = 100\n",
    "log_every = 10\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), lr=learning_rate)\n",
    "checkpoint_path = os.path.join('.', 'model', 'checkpoints', 'lstm')\n",
    "iterations = 0\n",
    "start_epoch = 0\n",
    "\n",
    "if has_checkpoint(checkpoint_path, is_best=True) or has_checkpoint(checkpoint_path):\n",
    "    if has_checkpoint(checkpoint_path, is_best=True):\n",
    "        print('Loading from best')\n",
    "        checkpoint = load_checkpoint(os.path.join(checkpoint_path, 'best.pth.tar'), lstm_model)\n",
    "    else:\n",
    "        print('Loading from last')\n",
    "        checkpoint = load_checkpoint(os.path.join(checkpoint_path, 'last.pth.tar'), lstm_model)\n",
    "    \n",
    "    best_dev_mae = checkpoint['best_dev_mae']\n",
    "    learning_rate = checkpoint['learning_rate']\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    iterations = checkpoint['iterations']\n",
    "\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    print(f'Epoch {epoch+1}/{epochs}')\n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, batch in enumerate(train_data_loader):\n",
    "        if iterations > batch_idx:\n",
    "            continue\n",
    "        \n",
    "        iterations += 1\n",
    "        \n",
    "        latent_factors = batch[2]\n",
    "        \n",
    "        lstm_model.train()\n",
    "        optimizer.zero_grad()\n",
    "        model_out = lstm_model(batch)\n",
    "        loss = criterion(model_out, latent_factors)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if iterations % save_every == 0:\n",
    "            print(f'Saving checkpoint at iteration {iterations}')\n",
    "            \n",
    "            save_checkpoint({\n",
    "                'epoch': epoch,\n",
    "                'iterations': iterations,\n",
    "                'state_dict': lstm_model.state_dict(),\n",
    "                'best_dev_mae': best_dev_mae,\n",
    "                'learning_rate': learning_rate,\n",
    "                'optim_dict': optimizer.state_dict(),\n",
    "            }, False, checkpoint_path)\n",
    "        \n",
    "        if iterations % eval_every == 0:\n",
    "            # switch model to evaluation mode\n",
    "            lstm_model.eval()\n",
    "\n",
    "            # calculate accuracy on validation set\n",
    "            dev_mae = 0\n",
    "            with torch.no_grad():\n",
    "                for dev_batch in valid_data_loader:\n",
    "                    dev_latent_factors = dev_batch[2]\n",
    "                    dev_model_out = lstm_model(dev_batch)\n",
    "                    dev_loss = criterion(dev_model_out, dev_latent_factors)\n",
    "                    dev_mae += dev_loss.item()\n",
    "                dev_mae /= valid_data_count\n",
    "\n",
    "            print(f'{time.time()-start_time} Epoch: {epoch} Iterations: {iterations} MAE: {loss.item()} Dev MAE: {dev_mae}')\n",
    "\n",
    "            # update best valiation set accuracy\n",
    "            if dev_mae > best_dev_mae:\n",
    "                best_dev_mae = dev_mae\n",
    "                print('Saving best model yet')\n",
    "                \n",
    "                save_checkpoint({\n",
    "                    'epoch': epoch,\n",
    "                    'iterations': iterations,\n",
    "                    'state_dict': lstm_model.state_dict(),\n",
    "                    'best_dev_mae': best_dev_mae,\n",
    "                    'learning_rate': learning_rate,\n",
    "                    'optim_dict': optimizer.state_dict(),\n",
    "                }, True, checkpoint_path)\n",
    "        \n",
    "        elif iterations % log_every == 0:\n",
    "            print(f'{time.time()-start_time} Epoch: {epoch} Iterations: {iterations} MAE: {loss.item()}')\n",
    "\n",
    "lstm_model.eval()\n",
    "\n",
    "# calculate accuracy on validation set\n",
    "dev_mae = 0\n",
    "with torch.no_grad():\n",
    "    for dev_batch in valid_data_loader:\n",
    "        dev_latent_factors = dev_batch[2]\n",
    "        dev_model_out = lstm_model(dev_batch)\n",
    "        dev_loss = criterion(dev_model_out, dev_latent_factors)\n",
    "        dev_mae += dev_loss.item()\n",
    "    dev_mae /= valid_data_count\n",
    "\n",
    "print(f'{time.time()-start_time} Epoch: {epoch} Iterations: {iterations} MAE: {loss.item()} Dev MAE: {dev_mae}')\n",
    "\n",
    "# update best valiation set accuracy\n",
    "if dev_mae > best_dev_mae:\n",
    "    best_dev_mae = dev_mae\n",
    "    print('Saving best model yet')\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch,\n",
    "        'iterations': iterations,\n",
    "        'state_dict': lstm_model.state_dict(),\n",
    "        'best_dev_mae': best_dev_mae,\n",
    "        'learning_rate': learning_rate,\n",
    "        'optim_dict': optimizer.state_dict(),\n",
    "    }, True, checkpoint_path)\n",
    "else:\n",
    "    load_checkpoint(os.path.join(checkpoint_path, 'last.pth.tar'), lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1848, 12])\n",
      "torch.Size([100, 2982, 12])\n",
      "torch.Size([100, 1933, 12])\n",
      "torch.Size([70, 2796, 12])\n"
     ]
    }
   ],
   "source": [
    "# Test the model.\n",
    "test_data_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                                batch_size=100,\n",
    "                                                collate_fn=collate_fn)\n",
    "\n",
    "lstm_model.eval()\n",
    "\n",
    "test_mae = 0\n",
    "with torch.no_grad():\n",
    "    for test_batch in test_data_loader:\n",
    "        print(test_batch[0].shape)\n",
    "        test_latent_factors = test_batch[2]\n",
    "        test_model_out = lstm_model(test_batch)\n",
    "        test_loss = criterion(test_model_out, test_latent_factors)\n",
    "        test_mae += test_loss.item()\n",
    "    test_mae /= test_data_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Some Recommendations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we get the user factors for these new users.\n",
    "test_user_factors = model.user_factors[:test_user_item_matrix.shape[0], :]\n",
    "\n",
    "valid_songs = song_subset.get_trainable_songs([train_tpd, val_msc_visible, val_msc_hidden, test_msc_visible, test_msc_hidden])\n",
    "valid_songs &= set(song_id_to_track_id.keys())\n",
    "valid_song_list = list(valid_songs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import lil_matrix, csr_matrix\n",
    "\n",
    "full_msd = MillionSongDataset__Preloaded(song_id_to_track_id, valid_song_list, train_item_factors, SubsetDataset)\n",
    "full_item_factors = lil_matrix((len(valid_song_list), 50), dtype='f')\n",
    "\n",
    "full_data_loader = torch.utils.data.DataLoader(dataset=full_msd,\n",
    "                                               batch_size=100,\n",
    "                                               collate_fn=collate_fn)\n",
    "\n",
    "for batch_idx, batch in enumerate(full_data_loader):\n",
    "    output = lstm_model(batch)\n",
    "    output = output.to('cpu').detach().numpy()\n",
    "    full_item_factors[batch_idx*100:min(batch_idx*100 + 100, len(valid_song_list))] = lil_matrix(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_item_factors = full_item_factors.tocsr()\n",
    "test_user_factors = csr_matrix(test_user_factors)\n",
    "lstm_recommendation_mat = test_user_factors.dot(full_item_factors.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<18042x10 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 180420 stored elements in LInked List format>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max_n(row_data, row_indices, n):\n",
    "    # https://stackoverflow.com/questions/31790819/scipy-sparse-csr-matrix-how-to-get-top-ten-values-and-indices\n",
    "    i = row_data[0].argsort()[0, -n:]\n",
    "    top_values = row_data[0, i]\n",
    "    top_indices = row_indices[i]  # do the sparse indices matter?\n",
    "    return top_values, top_indices, i\n",
    "\n",
    "def get_recommendations_all(recommendation_mat, n=10):\n",
    "    recommendations = lil_matrix((recommendation_mat.shape[0], n), dtype='int')\n",
    "    for r in range(recommendation_mat.shape[0]):\n",
    "        max_songs = max_n(recommendation_mat[r].todense(), np.arange(recommendation_mat.shape[1]), n)[1]\n",
    "        recommendations[r, :] = lil_matrix(max_songs)\n",
    "    return recommendations\n",
    "\n",
    "lstm_recommendations = get_recommendations_all(lstm_recommendation_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0015119047619047618"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_songs, actual_songs = build_predicted_and_actual_songs(lstm_recommendations.todense(), actual_user_songs)\n",
    "metrics.mean_average_precision(predicted_songs, actual_songs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
